# 0009 — Replay Engine (Shadow-Mode Validation)

## Context

The recorder (0008) captures raw Bybit mainnet WebSocket data to SQLite. The backtest engine replays historical ticker data through GridEngine to simulate trades. The comparator validates backtest-vs-live trade accuracy.

The **replay engine** closes the loop: it reads **recorded** mainnet data from the recorder's database, feeds it through the same GridEngine + simulated order book used by the backtest engine, and compares the **simulated trades** against the **real executions** that were recorded alongside the market data. This is the core shadow-mode validation pipeline: `record → replay → compare → report`.

The key difference from the backtest engine: the replay engine operates on data captured by the recorder (which uses fixed recorder UUIDs and a `run_id` per session), and its "ground truth" is the recorded private executions — not a separate live gridbot run.

---

## Architecture

```
apps/replay/
├── conf/
│   └── replay.yaml.example
├── src/replay/
│   ├── __init__.py
│   ├── main.py              # CLI entry point
│   ├── config.py             # YAML config model (Pydantic)
│   └── engine.py             # Replay orchestrator
├── tests/
│   ├── conftest.py
│   ├── test_config.py
│   ├── test_engine.py
│   └── test_main.py
└── pyproject.toml
```

---

## Core Design

### What the replay engine does

1. Reads recorded **TickerSnapshot** rows from the recorder DB for a given symbol + time range (reuses `HistoricalDataProvider` from backtest)
2. Feeds each tick through `BacktestRunner` (which wraps `GridEngine` + `BacktestOrderManager` + `BacktestPositionTracker`) — identical to the backtest engine's tick processing, including two-phase equity timing
3. Collects simulated trades in a `BacktestSession`
4. Loads recorded **PrivateExecution** rows from the same DB as ground truth (reuses `LiveTradeLoader` from comparator — it queries by `run_id`)
5. Runs `TradeMatcher` + `calculate_metrics()` to compare simulated vs recorded trades
6. Outputs comparison report via `ComparatorReporter`

### What it does NOT do

- No new fill simulator or order manager — reuses backtest's `TradeThroughFillSimulator` + `BacktestOrderManager`
- No new data provider — reuses backtest's `HistoricalDataProvider`
- No new trade loader — reuses comparator's `LiveTradeLoader` (for recorded executions) and `BacktestTradeLoader` (for simulated trades)
- No new matching or metrics — reuses comparator's `TradeMatcher` + `calculate_metrics()`
- No new reporter — reuses comparator's `ComparatorReporter`

### Why not just use the comparator's `--backtest-config` mode?

The comparator's config mode (`_load_backtest_from_config`) already runs a backtest and compares against live trades. However:

1. It requires a **live gridbot `run_id`** — the comparator's `LiveTradeLoader` queries `PrivateExecution` by `run_id`. The recorder uses its own fixed `run_id` per session, which is compatible, but the comparator CLI requires `--run-id` to be specified.
2. The comparator has no concept of **which DB contains the recorded data** vs which DB contains the backtest data — it assumes one shared DB.
3. The replay engine needs a dedicated CLI that takes a **recorder database path** and a **recorder run_id** (or auto-discovers the latest run), plus a grid strategy config to replay against.

The replay engine is a thin orchestrator that wires existing components together with a purpose-built CLI. It could eventually be folded into the comparator as a `--replay` mode, but starting as a separate app keeps concerns clean.

---

## Files to Create

### 1. `apps/replay/pyproject.toml`

Workspace package following the recorder/backtest pattern. Dependencies:
- `backtest` (workspace) — `BacktestEngine`, `BacktestRunner`, `HistoricalDataProvider`, `BacktestSession`, `BacktestReporter`
- `comparator` (workspace) — `LiveTradeLoader`, `BacktestTradeLoader`, `TradeMatcher`, `calculate_metrics`, `ComparatorReporter`, `EquityComparator`
- `gridcore` (workspace) — `GridEngine`, events, intents
- `grid-db` (workspace) — `DatabaseFactory`, models, repositories
- `pyyaml>=6.0`
- `pydantic>=2.0`

### 2. `apps/replay/src/replay/config.py`

**`ReplayConfig`** (Pydantic BaseModel):
- `database_url: str` — path to recorder SQLite DB (default: `sqlite:///recorder.db`)
- `run_id: Optional[str]` — recorder run_id to load ground-truth executions from; if omitted, uses latest `"recording"` run
- `symbol: str` — symbol to replay (e.g., `"BTCUSDT"`)
- `start_ts: Optional[datetime]` — replay start (defaults to run's `start_ts`)
- `end_ts: Optional[datetime]` — replay end (defaults to run's `end_ts`)
- `strategy: ReplayStrategyConfig` — grid strategy config for the replay

**`ReplayStrategyConfig`** (Pydantic BaseModel) — mirrors `BacktestStrategyConfig`:
- `tick_size: Decimal` — price tick size (e.g., `0.1`)
- `grid_count: int` — grid levels (default: 50)
- `grid_step: float` — step percentage (default: 0.2)
- `amount: str` — order sizing (default: `"x0.001"`)
- `commission_rate: Decimal` — default `0.0002`
- `initial_balance: Decimal` — default `10000`
- `enable_funding: bool` — default `True`
- `wind_down_mode: str` — `"leave_open"` or `"close_all"` (default: `"leave_open"`)

**`load_config(path)`** — loads YAML, searches `REPLAY_CONFIG_PATH` env var → `conf/replay.yaml` → `replay.yaml`.

### 3. `apps/replay/src/replay/engine.py`

**`ReplayEngine`** class — the core orchestrator.

Constructor: `config: ReplayConfig`, `db: DatabaseFactory`

**`run() -> ReplayResult`**:

Algorithm:

1. **Resolve run_id**: If `config.run_id` is None, query DB for the latest `Run` with `run_type="recording"` and `status` in `("completed", "running")`. Extract its `run_id`, `start_ts`, `end_ts`.

2. **Resolve time range**: Use `config.start_ts` / `config.end_ts` if provided, otherwise use the run's `start_ts` / `end_ts`.

3. **Create BacktestEngine components** (mirrors `BacktestEngine._init_runner()`):
   - Build a `BacktestStrategyConfig` from `config.strategy`
   - Create `InstrumentInfoProvider.get(symbol)` for `qty_step` / `tick_size`
   - Create `TradeThroughFillSimulator()`
   - Create `BacktestOrderManager(fill_simulator, commission_rate)`
   - Create qty calculator from `config.strategy.amount`
   - Create `BacktestExecutor(order_manager, qty_calculator)`
   - Create long + short `BacktestPositionTracker`
   - Create `BacktestSession(initial_balance)`
   - Create `BacktestRunner(strategy_config, executor, session, long_tracker, short_tracker)`

4. **Create data provider**: `HistoricalDataProvider(db, symbol, start_ts, end_ts)` — reads TickerSnapshots from recorder DB.

5. **Replay loop** (mirrors `BacktestEngine._process_tick()`):
   ```
   for tick in data_provider:
       # Phase 1: process fills
       runner.process_fills(tick)
       # Phase 2: update equity
       unrealized = runner.long_tracker.calculate_unrealized_pnl(tick.last_price)
                  + runner.short_tracker.calculate_unrealized_pnl(tick.last_price)
       session.update_equity(tick.exchange_ts, unrealized)
       # Phase 3: execute tick intents
       runner.execute_tick(tick, wallet_balance=session.current_balance)
       # Optional: apply funding
       if funding_simulator.should_apply_funding(tick.exchange_ts):
           runner.apply_funding(funding_rate, tick.last_price)
           funding_simulator.mark_funding_applied(tick.exchange_ts)
   ```

6. **Wind down**: If `config.strategy.wind_down_mode == "close_all"`, force-close positions at last price (same as `BacktestEngine._wind_down()`).

7. **Finalize session**: `session.finalize(final_unrealized_pnl)`

8. **Load ground truth**: Use `LiveTradeLoader` with the recorder's `run_id` to load recorded executions as `NormalizedTrade` list. This works because the recorder writes `PrivateExecution` rows with `run_id` and `order_link_id`, which is exactly what `LiveTradeLoader.load()` queries.

9. **Load simulated trades**: Use `BacktestTradeLoader.load_from_session(session.trades)` to get simulated trades as `NormalizedTrade` list.

10. **Match & metrics**: `TradeMatcher().match(recorded_trades, simulated_trades)` → `calculate_metrics(match_result, config.price_tolerance, config.qty_tolerance)`

11. **Report**: `ComparatorReporter(match_result, metrics).export_all(output_dir)` + `print_summary()`

12. **Return** `ReplayResult(session, metrics, match_result)`.

**`ReplayResult`** (dataclass):
- `session: BacktestSession` — contains simulated trades, equity curve, metrics
- `metrics: ValidationMetrics` — comparison metrics
- `match_result: MatchResult` — matched/unmatched trades

### 4. `apps/replay/src/replay/main.py`

CLI entry point following the backtest/comparator pattern.

**CLI arguments**:
- `--config PATH` — replay YAML config
- `--database-url URL` — override config's database_url
- `--run-id UUID` — override config's run_id
- `--symbol SYMBOL` — override config's symbol
- `--start DATE` — override start (YYYY-MM-DD or ISO)
- `--end DATE` — override end
- `--output DIR` — output directory (default: `results/replay`)
- `--debug` — enable debug logging

**`async main()`**:
1. Parse args, load config, apply CLI overrides
2. Create `DatabaseFactory`
3. Create `ReplayEngine(config, db)`
4. `result = engine.run()`
5. Export reports to output dir
6. Print summary
7. Return exit code (0=success, 1=config error, 2=runtime error)

**`cli()`** — argparse wrapper, calls `asyncio.run(main(...))` (if needed; the replay is synchronous like backtest, so may just use regular `main()`)

### 5. `apps/replay/conf/replay.yaml.example`

```yaml
database_url: "sqlite:///recorder.db"
# run_id: "..."  # Optional: auto-discovers latest recording run
symbol: "BTCUSDT"

# Optional time range overrides (defaults to run's start/end)
# start_ts: "2025-02-20T00:00:00"
# end_ts: "2025-02-23T00:00:00"

strategy:
  tick_size: 0.1
  grid_count: 50
  grid_step: 0.2
  amount: "x0.001"
  commission_rate: 0.0002
  initial_balance: 10000
  enable_funding: true
  wind_down_mode: "leave_open"

output_dir: "results/replay"
price_tolerance: 0
qty_tolerance: 0.001
```

---

## Files to Modify

### 6. Root `pyproject.toml`

Add `apps/replay` to workspace members list.

### 7. `Makefile`

Add replay test target:
```
uv run pytest apps/replay/tests --cov=replay --cov-append -q
```

---

## Key Reuse Map

| Component | Source Package | Usage in Replay |
|-----------|---------------|-----------------|
| `HistoricalDataProvider` | `backtest` | Read TickerSnapshots from recorder DB |
| `BacktestRunner` | `backtest` | Two-phase tick processing with GridEngine |
| `BacktestOrderManager` | `backtest` | Simulated order book |
| `TradeThroughFillSimulator` | `backtest` | Fill logic |
| `BacktestExecutor` | `backtest` | Execute intents |
| `BacktestPositionTracker` | `backtest` | PnL tracking |
| `BacktestSession` | `backtest` | Results storage + metrics |
| `InstrumentInfoProvider` | `backtest` | Fetch qty_step/tick_size |
| `FundingSimulator` | `backtest` | 8hr funding application |
| `LiveTradeLoader` | `comparator` | Load recorded executions as ground truth |
| `BacktestTradeLoader` | `comparator` | Convert simulated trades to NormalizedTrade |
| `TradeMatcher` | `comparator` | Match simulated vs recorded trades |
| `calculate_metrics` | `comparator` | Validation metrics |
| `ComparatorReporter` | `comparator` | CSV + console report |
| `GridEngine` | `gridcore` | Core strategy logic |
| `DatabaseFactory` | `grid_db` | DB access |

---

## Algorithm: Auto-Discover Latest Run

When `run_id` is not specified:

1. Query `Run` table: `SELECT * FROM runs WHERE run_type = 'recording' ORDER BY start_ts DESC LIMIT 1`
2. Use the recorder's fixed `user_id` (`00000000-0000-0000-0000-000000000001`) to filter if needed
3. Extract `run_id`, `start_ts`, `end_ts` from the row
4. If no recording runs found, raise `ValueError("No recording runs found in database")`

This requires adding a query method to `RunRepository` or querying directly in the engine. Prefer adding `get_latest_by_type(run_type: str) -> Optional[Run]` to `RunRepository`.

---

## Tests

### `test_config.py`
- Valid YAML parses correctly
- Missing file raises `FileNotFoundError`
- Default values applied (initial_balance, grid params, etc.)
- CLI overrides applied to config
- Auto-discover run_id when omitted

### `test_engine.py`
- Replay with InMemoryDataProvider produces expected trades
- Two-phase tick processing matches backtest behavior
- Simulated trades match against mock recorded executions
- Wind-down mode works (leave_open vs close_all)
- Funding applied at correct intervals
- Empty recorded executions → all simulated trades are "backtest_only"
- Empty ticker data → no simulated trades, no match

### `test_main.py`
- CLI argument parsing
- Date parsing (YYYY-MM-DD and ISO)
- Exit codes (0, 1, 2)
- Output directory creation
- `_close_dangling_coro()` pattern for mocked `asyncio.run` (if async)
